# Cross-Attention-mechanism-3D-images
I am aware that the current organization of the repository is a MESS

Cross Attention mechanism for 3D tensors in pytorch for DL models which can be used as input to CNN layers and so forth. Here Cross attention or merging two seperate input tensors, and gives same output size.

Intial apply tranformer attento to each input to calc quer, key, value foolwed by torch matmul applied to tensor1 + attention calculated from tensor2


Inlcuded C/cuda and C++ versions of the cross attention transformer as weel as python example of how this can be incoporated into a basic GAN generator if u have multiple inputs

TODO:
In C and C++
- Reader
- GAN training and code iteration
- Update read me
