# Cross-Attention-mechanism-3D-images


Cross Attention mechanism for 3D tensors in pytorch for DL models which can be used as input to CNN layers and so forth. Here Cross attention or merging two seperate input tensors, and gives same output size.

Intial apply tranformer attento to each input to calc quer, key, value foolwed by torch matmul applied to tensor1 + attention calculated from tensor2


Any 
